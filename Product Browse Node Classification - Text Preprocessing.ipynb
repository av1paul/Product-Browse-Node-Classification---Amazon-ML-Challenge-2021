{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe309a9d",
   "metadata": {},
   "source": [
    "## Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4832a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from word2number import w2n\n",
    "import string\n",
    "from itertools import groupby \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import spacy\n",
    "import contractions\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import textdistance\n",
    "from tqdm import tqdm\n",
    "from nltk import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import csv\n",
    "from ast import literal_eval as make_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b10230",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset/test.csv', escapechar=\"\\\\\", quoting = csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937235b8",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387ce60",
   "metadata": {},
   "source": [
    "## What is text preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed01744",
   "metadata": {},
   "source": [
    "### To preprocess your text simply means to bring your text into a form that is predictable and analyzable for your task. A task here is a combination of approach and domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4adc20b",
   "metadata": {},
   "source": [
    "## Instruction for setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290ffcb",
   "metadata": {},
   "source": [
    "### Virtual environment\n",
    "- First go to commandline/terminal and make a virtual environment using virtualenv.\n",
    "- Command for creating virtual environment: virtualenv name.\n",
    "- Activate virtual environment: Linux/mac:-source name/bin/activate , windows:-name\\Scripts\\activate\n",
    "- Deactivate virtual environment: deactivate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f1ce1",
   "metadata": {},
   "source": [
    "### install the following python libraries:\n",
    "- jupyter\n",
    "- beautifulsoup4\n",
    "- nltk\n",
    "- pandas\n",
    "- tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c274548a",
   "metadata": {},
   "source": [
    "## Text Preprocessing which will be performed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd55024",
   "metadata": {},
   "source": [
    "- Remove duplicates\n",
    "- Remove null values in titles\n",
    "- Selecting 100 rows in random corresponding to each browse node id, and dropping rows whose browse node id frequency is less than 100.\n",
    "- Converting the text to lowercase.\n",
    "- Removal of any html markups.\n",
    "- Removal of line breaks.\n",
    "- Removal of website links.\n",
    "- Convert non-ascii characters to ascii.\n",
    "- Expand contractions.\n",
    "- Remove digits from strings(optional).\n",
    "- Remove all emojis.\n",
    "- Remove redundant characters to 2 or 1(optional).\n",
    "- Remove redundant punctuations to 1.\n",
    "- Remove all punctuations except . , !.\n",
    "- Remove all punctuations.\n",
    "- Remove extra whitespace in between characters.\n",
    "- Remove extra whitespace at the ends.\n",
    "- Stemming(optional)\n",
    "- Stop words removal(optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b7980",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4e429",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a378e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDups(s):\n",
    "    \"\"\"Function to remove any duplicate continuous punctuation and get into one\"\"\"\n",
    "    punc = set(string.punctuation)\n",
    "    newtext = []\n",
    "    for k, g in groupby(s):\n",
    "        if k in punc:\n",
    "            newtext.append(k)\n",
    "        else:\n",
    "            newtext.extend(g)\n",
    "\n",
    "    newtext=''.join(newtext)\n",
    "    return(newtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b4144",
   "metadata": {},
   "source": [
    "## Remove emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "140cc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis(text, remove=True):\n",
    "    \"\"\"To remove all emojis from the text\"\"\"\n",
    "    if remove==True:\n",
    "        emoji_pattern=re.compile(\"[\"\n",
    "                         u\"\\U0001F600-\\U0001F64F\"\n",
    "                         u\"\\U0001F300-\\U0001F5FF\"\n",
    "                         u\"\\U0001F680-\\U0001F6FF\"\n",
    "                         u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                         \"]+\",flags=re.UNICODE)\n",
    "        t=emoji_pattern.sub(r'',text).strip()\n",
    "        return t\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca99b3b7",
   "metadata": {},
   "source": [
    "## Remove certain punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02281ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_certain_punctuation(text, remove=True):\n",
    "    \"\"\"to remove all punctuations except . ! ?\"\"\"\n",
    "    if remove==True:\n",
    "        text=re.sub(\"[^.,!'?a-zA-Z0-9 \\n]\",' ',text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60bd6bb",
   "metadata": {},
   "source": [
    "## Remove all punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dafca4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_punctuation(text, remove=False):\n",
    "    \"\"\"to remove all punctuations \"\"\"\n",
    "   \n",
    "    if remove==True:\n",
    "        text=re.sub(\"[^a-zA-Z0-9 \\n]\",' ',text) \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37550f04",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "925805b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text, apply=False):\n",
    "    \"\"\"Function to stem the words\"\"\"\n",
    "    if apply==True:\n",
    "        text1=[]\n",
    "        text1.append(text)\n",
    "        text1=''.join(text1).split()\n",
    "        for i in range(len(text1)):\n",
    "            text1[i]=s_stemmer.stem(text1[i])\n",
    "        tex=' '.join(text1)\n",
    "        return tex\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a04a08",
   "metadata": {},
   "source": [
    "## Remove redundant characters to 2 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "133defc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redun_to_2_or_1(text,choice=2,apply=True):\n",
    "    if apply==True:\n",
    "        if choice==1:\n",
    "            repeat_pattern=re.compile(r'(\\w)\\1*')\n",
    "            match_substitution=r'\\1'\n",
    "            new_word=repeat_pattern.sub(match_substitution,text)\n",
    "            return new_word\n",
    "\n",
    "        if choice==2:\n",
    "            regr=re.compile(r'(a){3,}')\n",
    "            regr0=re.compile(r'(b){3,}')\n",
    "            regr1=re.compile(r'(c){3,}')\n",
    "            regr2=re.compile(r'(d){3,}')\n",
    "            regr3=re.compile(r'(e){3,}')\n",
    "            regr4=re.compile(r'(f){3,}')\n",
    "            regr5=re.compile(r'(g){3,}')\n",
    "            regr6=re.compile(r'(h){3,}')\n",
    "            regr7=re.compile(r'(i){3,}')\n",
    "            regr8=re.compile(r'(j){3,}')\n",
    "            regr9=re.compile(r'(k){3,}')\n",
    "            regr10=re.compile(r'(l){3,}')\n",
    "            regr11=re.compile(r'(m){3,}')\n",
    "            regr12=re.compile(r'(n){3,}')\n",
    "            regr13=re.compile(r'(o){3,}')\n",
    "            regr14=re.compile(r'(p){3,}')\n",
    "            regr15=re.compile(r'(q){3,}')\n",
    "            regr16=re.compile(r'(r){3,}')\n",
    "            regr17=re.compile(r'(s){3,}')\n",
    "            regr18=re.compile(r'(t){3,}')\n",
    "            regr19=re.compile(r'(u){3,}')\n",
    "            regr20=re.compile(r'(v){3,}')\n",
    "            regr21=re.compile(r'(w){3,}')\n",
    "            regr22=re.compile(r'(x){3,}')\n",
    "            regr23=re.compile(r'(y){3,}')\n",
    "            regr24=re.compile(r'(z){3,}')\n",
    "            new_word=re.sub(regr,\"aa\",text)\n",
    "            new_word=re.sub(regr0,\"bb\",new_word)\n",
    "            new_word=re.sub(regr1,\"cc\",new_word)\n",
    "            new_word=re.sub(regr2,\"dd\",new_word)\n",
    "            new_word=re.sub(regr3,\"ee\",new_word)\n",
    "            new_word=re.sub(regr4,\"ff\",new_word)\n",
    "            new_word=re.sub(regr5,\"gg\",new_word)\n",
    "            new_word=re.sub(regr6,\"hh\",new_word)\n",
    "            new_word=re.sub(regr7,\"ii\",new_word)\n",
    "            new_word=re.sub(regr8,\"jj\",new_word)\n",
    "            new_word=re.sub(regr9,\"kk\",new_word)\n",
    "            new_word=re.sub(regr10,\"ll\",new_word)\n",
    "            new_word=re.sub(regr11,\"mm\",new_word)\n",
    "            new_word=re.sub(regr12,\"nn\",new_word)\n",
    "            new_word=re.sub(regr13,\"oo\",new_word)\n",
    "            new_word=re.sub(regr14,\"pp\",new_word)\n",
    "            new_word=re.sub(regr15,\"qq\",new_word)\n",
    "            new_word=re.sub(regr16,\"rr\",new_word)\n",
    "            new_word=re.sub(regr17,\"ss\",new_word)\n",
    "            new_word=re.sub(regr18,\"tt\",new_word)\n",
    "            new_word=re.sub(regr19,\"uu\",new_word)\n",
    "            new_word=re.sub(regr20,\"vv\",new_word)\n",
    "            new_word=re.sub(regr21,\"ww\",new_word)\n",
    "            new_word=re.sub(regr22,\"xx\",new_word)\n",
    "            new_word=re.sub(regr23,\"yy\",new_word)\n",
    "            new_word=re.sub(regr24,\"zz\",new_word)\n",
    "        return new_word\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20adf1",
   "metadata": {},
   "source": [
    "## Word to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9a23bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_num(text, apply=False):\n",
    "    if apply==True:\n",
    "        text1=nlp(text)\n",
    "        l=[]\n",
    "        a=[]\n",
    "        r=[]\n",
    "        for sent in text1.sents:\n",
    "            l.append(sent)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(l)):\n",
    "            for ent in l[i].ents:\n",
    "                if ent.label_=='CARDINAL':\n",
    "                    r.append(str(ent))\n",
    "        a=r.copy()\n",
    "\n",
    "        for i in range(len(r)):\n",
    "            try:\n",
    "                if r[i].isdigit()==False:\n",
    "                    a[i]=str(w2n.word_to_num(r[i]))\n",
    "            except ValueError as error:\n",
    "                continue\n",
    "        for i in range(len(r)):\n",
    "            text=text.replace(r[i],a[i])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4ee757",
   "metadata": {},
   "source": [
    "## Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb22b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=contractions.CONTRACTION_MAP):\n",
    "    \"\"\"Function to perform contractions\"\"\"\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),\n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())\n",
    "#         expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "#     expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb0284",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c95daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_words_removal(text, apply=False):\n",
    "    \n",
    "    if apply==True:\n",
    "        a=[]\n",
    "        n1=[]\n",
    "        b=[]\n",
    "        a.append(text)\n",
    "        n1=''.join(a).split()\n",
    "        for i in range(len(n1)):\n",
    "            if nlp.vocab[n1[i]].is_stop==False:\n",
    "                b.append(n1[i])\n",
    "        tex=' '.join(b)\n",
    "        return(tex)\n",
    "    else:\n",
    "        return(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c75d7",
   "metadata": {},
   "source": [
    "## Final preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcceb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"Function to perform all types of preprocessing required\"\"\"\n",
    "      \n",
    "    #to convert all code into lower case\n",
    "    text=str(text).lower()\n",
    "    # remove html markup\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    regex=re.compile(r'[\\n\\r\\t\\xa0]')\n",
    "    text=regex.sub(\" \",text)\n",
    "    # remove website links\n",
    "    text=re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''','',text)\n",
    "    #to convert the non-ascii characters to ascii\n",
    "    text = unidecode(text)\n",
    "    text=expand_contractions(text)\n",
    "    #to remove strings with digits\n",
    "    #text=re.sub(r'\\w*\\d\\w*',' ',text)\n",
    "    #to remove all emojis\n",
    "    text=remove_emojis(text)\n",
    "    text=remove_redun_to_2_or_1(text)\n",
    "    #to remove duplicate punctuations\n",
    "    text=removeDups(text)\n",
    "    #to remove all punctuations except . ! ?\n",
    "    text=remove_certain_punctuation(text)\n",
    "    text=expand_contractions(text)\n",
    "    #remove non-ascii and digits\n",
    "    text=remove_all_punctuation(text)\n",
    "    #to remove extra whitespace in between characters\n",
    "    text=re.sub(' +', ' ',text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #to convert all word numbers to actual number\n",
    "    text=word_to_num(text)\n",
    "    #remove whitespace\n",
    "    text=text.strip()\n",
    "   \n",
    "    text=stemming(text)\n",
    "    text=stop_words_removal(text)\n",
    "    \n",
    "    #text=spell_correction(text)\n",
    "    #to understand the sentiment probability\n",
    "    return text\n",
    "  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "072f8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=data['TITLE'].tolist()\n",
    "p_id=data['PRODUCT_ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "592ad3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|██████████████████████████████████████████████████████████████| 110775/110775 [01:21<00:00, 1362.60it/s]\n"
     ]
    }
   ],
   "source": [
    "lists=[]\n",
    "for i in tqdm(range(len(l1)), desc=\"progress\"):\n",
    "    lists.append(preprocess(l1[i]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a3784e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_data=pd.DataFrame({'Product_id':p_id,'Titles':lists})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f8f9829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9919"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svm_data['Browse_node'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e88c9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_data.to_csv('Preprocessed test data for classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03137021",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_data=pd.read_csv('dataset/Preprocessed data for classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5065096",
   "metadata": {},
   "outputs": [],
   "source": [
    "tits=svm_data['Titles'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9946c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "progress: 100%|████████████████████████████████████████████████████████████| 2902953/2902953 [12:11<00:00, 3968.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(tits)),desc='progress'):\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    tits[i] = ' '.join(word for word in str(tits[i]).split() if word not in STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc53a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_id=svm_data['Browse_node'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f34b5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data=pd.DataFrame({'Titles':tits, 'Browse_node': browse_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dcc0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data.to_csv('Preprocessed data for classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3dbc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data.drop_duplicates(subset='Titles',keep=False, inplace=True)\n",
    "class_data.to_csv('Preprocessed data for classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c30d7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data=pd.read_csv('Preprocessed data for classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f1168c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "de=class_data.groupby(by='Browse_node', as_index=False)['Titles'].count().rename(columns={\"Titles\": \"frequency\"}).sort_values('frequency',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c66376",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder=de[de['frequency']>100]\n",
    "li=finder['Browse_node'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebca41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=class_data[class_data['Browse_node'].isin(li)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3152c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "der=df.groupby('Browse_node',as_index=False).apply(lambda x:x.sample(100)).reset_index(level=0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf1c0dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Browse_node</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1654</td>\n",
       "      <td>9580</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1647</td>\n",
       "      <td>9502</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1648</td>\n",
       "      <td>9512</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1649</td>\n",
       "      <td>9520</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>2131</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>828</td>\n",
       "      <td>2137</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>2140</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2143</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2477</td>\n",
       "      <td>215592</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Browse_node  frequency\n",
       "0               0        100\n",
       "1654         9580        100\n",
       "1647         9502        100\n",
       "1648         9512        100\n",
       "1649         9520        100\n",
       "...           ...        ...\n",
       "827          2131        100\n",
       "828          2137        100\n",
       "829          2140        100\n",
       "830          2143        100\n",
       "2477       215592        100\n",
       "\n",
       "[2478 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "der.groupby(by='Browse_node', as_index=False)['Titles'].count().rename(columns={\"Titles\": \"frequency\"}).sort_values('frequency',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2073bdc",
   "metadata": {},
   "source": [
    "## Observations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc48a49",
   "metadata": {},
   "source": [
    "After removing all the nodes which can lead to overfitting, we have around 2478 rows of browse ids and 247800 documents approximately"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
